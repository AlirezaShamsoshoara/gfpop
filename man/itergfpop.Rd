% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gfpop.R
\name{itergfpop}
\alias{itergfpop}
\title{Graph-constrained functional pruning optimal partitioning iterated}
\usage{
itergfpop(vectData = c(0), vectWeight = c(0), mygraph,
  type = "gauss", K = Inf, a = 0, min = -Inf, max = Inf,
  iter.max = 100, D.init = 1)
}
\arguments{
\item{vectData}{vector of data to segment}

\item{vectWeight}{vector of weights (positive numbers) same size as vectData}

\item{mygraph}{dataframe of class graph to constraint the changepoint dynamic programming algorithm}

\item{type}{a string defining the type of cost to use. "gauss", "poisson" or "binomial"}

\item{K}{a positive number. Threshold for the Biweight robust loss}

\item{a}{a positive number. Slope for the Huber robust loss}

\item{min}{minimal bound for the infered means}

\item{max}{maximal bound for the infered means}

\item{iter.max}{maximal number of iteration of the gfpop function}

\item{D.init}{initialisation of the number of segments}
}
\value{
a gfpop object = (changepoints, states, forced, means).
'changepoints' is the vector of changepoints (we give the last element of each segment).
'states' is the vector giving the state of each segment
'forced' is the vector specifying whether the constraints of the graph are active (=1) or not (=0)
'means' is the vector of successive means of each segment
'cost' is a number equal to the global cost of the graph-constrained segmentation
'Dvect' is a vector of integers. The successive tested D in the Birgé Massart penalty until convergence
}
\description{
Graph-contstrained functional pruning optimal partitionning iterated with a Birgé Massart like penalty
}
